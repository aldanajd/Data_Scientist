{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![CartPole Enviroment](Machine%20Learning/Deep%20Reinforcement%20Learning/Cartpole_intro_to_RL/Media/Cartpole-v1_enviroment.PNG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# System: Track Python version\n",
    "import sys\n",
    "# Enviroment\n",
    "import gym \n",
    "# Reinforcement Learning Agent and Policy\n",
    "from stable_baselines3 import A2C\n",
    "from stable_baselines3.common.evaluation import evaluate_policy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Enviroment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Naming (Selecting) the Enviroment\n",
    "environment_name = 'CartPole-v1'\n",
    "# Creating the Enviroment\n",
    "env = gym.make(environment_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing the Enviroment with Random Actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode:1 Score:15.0\n",
      "Episode:2 Score:12.0\n",
      "Episode:3 Score:21.0\n",
      "Episode:4 Score:21.0\n",
      "Episode:5 Score:13.0\n",
      "Episode:6 Score:16.0\n",
      "Episode:7 Score:37.0\n",
      "Episode:8 Score:18.0\n",
      "Episode:9 Score:20.0\n",
      "Episode:10 Score:14.0\n"
     ]
    }
   ],
   "source": [
    "# Number of Episodes to test\n",
    "episodes = 10\n",
    "\n",
    "for episode in range(1, episodes+1):\n",
    "    # Reset the Enviroment\n",
    "    state = env.reset()\n",
    "    done = False\n",
    "    score = 0 \n",
    "    \n",
    "    while not done:\n",
    "        env.render()\n",
    "        # Selecting a Random Action\n",
    "        action = env.action_space.sample()\n",
    "        # Applying the Action to the Enviroment\n",
    "        n_state, reward, done, info = env.step(action)\n",
    "        score+=reward\n",
    "    # Printing the Score per Episode\n",
    "    print('Episode:{} Score:{}'.format(episode, score))\n",
    "    \n",
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n"
     ]
    }
   ],
   "source": [
    "# Selecting the Algorithm and Policy\n",
    "model = A2C('MlpPolicy', env, verbose = 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 212      |\n",
      "|    ep_rew_mean        | 212      |\n",
      "| time/                 |          |\n",
      "|    fps                | 959      |\n",
      "|    iterations         | 100      |\n",
      "|    time_elapsed       | 0        |\n",
      "|    total_timesteps    | 500      |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.571   |\n",
      "|    explained_variance | 0.000193 |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 1099     |\n",
      "|    policy_loss        | 1.02     |\n",
      "|    value_loss         | 2.25     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 142      |\n",
      "|    ep_rew_mean        | 142      |\n",
      "| time/                 |          |\n",
      "|    fps                | 966      |\n",
      "|    iterations         | 200      |\n",
      "|    time_elapsed       | 1        |\n",
      "|    total_timesteps    | 1000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.602   |\n",
      "|    explained_variance | 5.11e-05 |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 1199     |\n",
      "|    policy_loss        | -4.62    |\n",
      "|    value_loss         | 1.29e+03 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 87.3     |\n",
      "|    ep_rew_mean        | 87.3     |\n",
      "| time/                 |          |\n",
      "|    fps                | 968      |\n",
      "|    iterations         | 300      |\n",
      "|    time_elapsed       | 1        |\n",
      "|    total_timesteps    | 1500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.567   |\n",
      "|    explained_variance | 0.000106 |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 1299     |\n",
      "|    policy_loss        | 0.939    |\n",
      "|    value_loss         | 1.55     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 60.6     |\n",
      "|    ep_rew_mean        | 60.6     |\n",
      "| time/                 |          |\n",
      "|    fps                | 964      |\n",
      "|    iterations         | 400      |\n",
      "|    time_elapsed       | 2        |\n",
      "|    total_timesteps    | 2000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.669   |\n",
      "|    explained_variance | 0.000646 |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 1399     |\n",
      "|    policy_loss        | 0.541    |\n",
      "|    value_loss         | 1.3      |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 49.9     |\n",
      "|    ep_rew_mean        | 49.9     |\n",
      "| time/                 |          |\n",
      "|    fps                | 965      |\n",
      "|    iterations         | 500      |\n",
      "|    time_elapsed       | 2        |\n",
      "|    total_timesteps    | 2500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.566   |\n",
      "|    explained_variance | 8.29e-06 |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 1499     |\n",
      "|    policy_loss        | -26.3    |\n",
      "|    value_loss         | 2.62e+03 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 37.9     |\n",
      "|    ep_rew_mean        | 37.9     |\n",
      "| time/                 |          |\n",
      "|    fps                | 969      |\n",
      "|    iterations         | 600      |\n",
      "|    time_elapsed       | 3        |\n",
      "|    total_timesteps    | 3000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.519   |\n",
      "|    explained_variance | 0.305    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 1599     |\n",
      "|    policy_loss        | -1.47    |\n",
      "|    value_loss         | 11.1     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 37.5     |\n",
      "|    ep_rew_mean        | 37.5     |\n",
      "| time/                 |          |\n",
      "|    fps                | 951      |\n",
      "|    iterations         | 700      |\n",
      "|    time_elapsed       | 3        |\n",
      "|    total_timesteps    | 3500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.65    |\n",
      "|    explained_variance | -8.33    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 1699     |\n",
      "|    policy_loss        | 0.349    |\n",
      "|    value_loss         | 1.9      |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 42.9     |\n",
      "|    ep_rew_mean        | 42.9     |\n",
      "| time/                 |          |\n",
      "|    fps                | 948      |\n",
      "|    iterations         | 800      |\n",
      "|    time_elapsed       | 4        |\n",
      "|    total_timesteps    | 4000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.632   |\n",
      "|    explained_variance | -0.0283  |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 1799     |\n",
      "|    policy_loss        | 0.295    |\n",
      "|    value_loss         | 0.547    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 47.1     |\n",
      "|    ep_rew_mean        | 47.1     |\n",
      "| time/                 |          |\n",
      "|    fps                | 948      |\n",
      "|    iterations         | 900      |\n",
      "|    time_elapsed       | 4        |\n",
      "|    total_timesteps    | 4500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.617   |\n",
      "|    explained_variance | -8.9e-05 |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 1899     |\n",
      "|    policy_loss        | 0.234    |\n",
      "|    value_loss         | 0.35     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 50       |\n",
      "|    ep_rew_mean        | 50       |\n",
      "| time/                 |          |\n",
      "|    fps                | 913      |\n",
      "|    iterations         | 1000     |\n",
      "|    time_elapsed       | 5        |\n",
      "|    total_timesteps    | 5000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.596   |\n",
      "|    explained_variance | -0.0214  |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 1999     |\n",
      "|    policy_loss        | 0.312    |\n",
      "|    value_loss         | 0.208    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 53       |\n",
      "|    ep_rew_mean        | 53       |\n",
      "| time/                 |          |\n",
      "|    fps                | 914      |\n",
      "|    iterations         | 1100     |\n",
      "|    time_elapsed       | 6        |\n",
      "|    total_timesteps    | 5500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.668   |\n",
      "|    explained_variance | 0.0164   |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 2099     |\n",
      "|    policy_loss        | 0.159    |\n",
      "|    value_loss         | 0.0974   |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 52.7      |\n",
      "|    ep_rew_mean        | 52.7      |\n",
      "| time/                 |           |\n",
      "|    fps                | 920       |\n",
      "|    iterations         | 1200      |\n",
      "|    time_elapsed       | 6         |\n",
      "|    total_timesteps    | 6000      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.615    |\n",
      "|    explained_variance | -8.38e-05 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 2199      |\n",
      "|    policy_loss        | 0.0814    |\n",
      "|    value_loss         | 0.0295    |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 54.6     |\n",
      "|    ep_rew_mean        | 54.6     |\n",
      "| time/                 |          |\n",
      "|    fps                | 925      |\n",
      "|    iterations         | 1300     |\n",
      "|    time_elapsed       | 7        |\n",
      "|    total_timesteps    | 6500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.605   |\n",
      "|    explained_variance | -0.0535  |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 2299     |\n",
      "|    policy_loss        | 0.0188   |\n",
      "|    value_loss         | 0.00158  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 57.7     |\n",
      "|    ep_rew_mean        | 57.7     |\n",
      "| time/                 |          |\n",
      "|    fps                | 927      |\n",
      "|    iterations         | 1400     |\n",
      "|    time_elapsed       | 7        |\n",
      "|    total_timesteps    | 7000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.535   |\n",
      "|    explained_variance | -1.3     |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 2399     |\n",
      "|    policy_loss        | 0.00123  |\n",
      "|    value_loss         | 2.23e-05 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 63.2     |\n",
      "|    ep_rew_mean        | 63.2     |\n",
      "| time/                 |          |\n",
      "|    fps                | 929      |\n",
      "|    iterations         | 1500     |\n",
      "|    time_elapsed       | 8        |\n",
      "|    total_timesteps    | 7500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.538   |\n",
      "|    explained_variance | -0.382   |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 2499     |\n",
      "|    policy_loss        | 0.00149  |\n",
      "|    value_loss         | 1.3e-05  |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 64.5      |\n",
      "|    ep_rew_mean        | 64.5      |\n",
      "| time/                 |           |\n",
      "|    fps                | 928       |\n",
      "|    iterations         | 1600      |\n",
      "|    time_elapsed       | 8         |\n",
      "|    total_timesteps    | 8000      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.622    |\n",
      "|    explained_variance | -1.17e+03 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 2599      |\n",
      "|    policy_loss        | 0.000508  |\n",
      "|    value_loss         | 6.29e-06  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 71.1     |\n",
      "|    ep_rew_mean        | 71.1     |\n",
      "| time/                 |          |\n",
      "|    fps                | 929      |\n",
      "|    iterations         | 1700     |\n",
      "|    time_elapsed       | 9        |\n",
      "|    total_timesteps    | 8500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.519   |\n",
      "|    explained_variance | 0.187    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 2699     |\n",
      "|    policy_loss        | 0.00141  |\n",
      "|    value_loss         | 1.34e-05 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 75       |\n",
      "|    ep_rew_mean        | 75       |\n",
      "| time/                 |          |\n",
      "|    fps                | 929      |\n",
      "|    iterations         | 1800     |\n",
      "|    time_elapsed       | 9        |\n",
      "|    total_timesteps    | 9000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.494   |\n",
      "|    explained_variance | -0.0899  |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 2799     |\n",
      "|    policy_loss        | 0.00432  |\n",
      "|    value_loss         | 5.08e-05 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 75.9     |\n",
      "|    ep_rew_mean        | 75.9     |\n",
      "| time/                 |          |\n",
      "|    fps                | 925      |\n",
      "|    iterations         | 1900     |\n",
      "|    time_elapsed       | 10       |\n",
      "|    total_timesteps    | 9500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.589   |\n",
      "|    explained_variance | -10.4    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 2899     |\n",
      "|    policy_loss        | 0.000948 |\n",
      "|    value_loss         | 1.18e-05 |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 79.6      |\n",
      "|    ep_rew_mean        | 79.6      |\n",
      "| time/                 |           |\n",
      "|    fps                | 926       |\n",
      "|    iterations         | 2000      |\n",
      "|    time_elapsed       | 10        |\n",
      "|    total_timesteps    | 10000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.527    |\n",
      "|    explained_variance | -17.2     |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 2999      |\n",
      "|    policy_loss        | -8.88e-05 |\n",
      "|    value_loss         | 3.81e-07  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 84.3      |\n",
      "|    ep_rew_mean        | 84.3      |\n",
      "| time/                 |           |\n",
      "|    fps                | 930       |\n",
      "|    iterations         | 2100      |\n",
      "|    time_elapsed       | 11        |\n",
      "|    total_timesteps    | 10500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.615    |\n",
      "|    explained_variance | -23.2     |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 3099      |\n",
      "|    policy_loss        | -0.000187 |\n",
      "|    value_loss         | 8.81e-07  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 88.7     |\n",
      "|    ep_rew_mean        | 88.7     |\n",
      "| time/                 |          |\n",
      "|    fps                | 930      |\n",
      "|    iterations         | 2200     |\n",
      "|    time_elapsed       | 11       |\n",
      "|    total_timesteps    | 11000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.543   |\n",
      "|    explained_variance | -0.182   |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 3199     |\n",
      "|    policy_loss        | 0.000279 |\n",
      "|    value_loss         | 3.12e-07 |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 92        |\n",
      "|    ep_rew_mean        | 92        |\n",
      "| time/                 |           |\n",
      "|    fps                | 930       |\n",
      "|    iterations         | 2300      |\n",
      "|    time_elapsed       | 12        |\n",
      "|    total_timesteps    | 11500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.557    |\n",
      "|    explained_variance | -3.95     |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 3299      |\n",
      "|    policy_loss        | -3.56e-05 |\n",
      "|    value_loss         | 1e-08     |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 97.5     |\n",
      "|    ep_rew_mean        | 97.5     |\n",
      "| time/                 |          |\n",
      "|    fps                | 929      |\n",
      "|    iterations         | 2400     |\n",
      "|    time_elapsed       | 12       |\n",
      "|    total_timesteps    | 12000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.603   |\n",
      "|    explained_variance | -43.6    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 3399     |\n",
      "|    policy_loss        | 0.000256 |\n",
      "|    value_loss         | 1.21e-06 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 103      |\n",
      "|    ep_rew_mean        | 103      |\n",
      "| time/                 |          |\n",
      "|    fps                | 924      |\n",
      "|    iterations         | 2500     |\n",
      "|    time_elapsed       | 13       |\n",
      "|    total_timesteps    | 12500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.559   |\n",
      "|    explained_variance | -2.19    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 3499     |\n",
      "|    policy_loss        | 0.000762 |\n",
      "|    value_loss         | 6.71e-06 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 105      |\n",
      "|    ep_rew_mean        | 105      |\n",
      "| time/                 |          |\n",
      "|    fps                | 924      |\n",
      "|    iterations         | 2600     |\n",
      "|    time_elapsed       | 14       |\n",
      "|    total_timesteps    | 13000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.489   |\n",
      "|    explained_variance | 0.736    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 3599     |\n",
      "|    policy_loss        | 0.00218  |\n",
      "|    value_loss         | 1.95e-05 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 109      |\n",
      "|    ep_rew_mean        | 109      |\n",
      "| time/                 |          |\n",
      "|    fps                | 925      |\n",
      "|    iterations         | 2700     |\n",
      "|    time_elapsed       | 14       |\n",
      "|    total_timesteps    | 13500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.379   |\n",
      "|    explained_variance | 0.0568   |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 3699     |\n",
      "|    policy_loss        | -0.41    |\n",
      "|    value_loss         | 1.82e+03 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 112      |\n",
      "|    ep_rew_mean        | 112      |\n",
      "| time/                 |          |\n",
      "|    fps                | 924      |\n",
      "|    iterations         | 2800     |\n",
      "|    time_elapsed       | 15       |\n",
      "|    total_timesteps    | 14000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.487   |\n",
      "|    explained_variance | 0.09     |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 3799     |\n",
      "|    policy_loss        | -0.0149  |\n",
      "|    value_loss         | 0.00114  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 116      |\n",
      "|    ep_rew_mean        | 116      |\n",
      "| time/                 |          |\n",
      "|    fps                | 920      |\n",
      "|    iterations         | 2900     |\n",
      "|    time_elapsed       | 15       |\n",
      "|    total_timesteps    | 14500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.381   |\n",
      "|    explained_variance | -43.3    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 3899     |\n",
      "|    policy_loss        | -3.61    |\n",
      "|    value_loss         | 242      |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 119      |\n",
      "|    ep_rew_mean        | 119      |\n",
      "| time/                 |          |\n",
      "|    fps                | 920      |\n",
      "|    iterations         | 3000     |\n",
      "|    time_elapsed       | 16       |\n",
      "|    total_timesteps    | 15000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.427   |\n",
      "|    explained_variance | -5.91    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 3999     |\n",
      "|    policy_loss        | -4.62    |\n",
      "|    value_loss         | 58.3     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 123      |\n",
      "|    ep_rew_mean        | 123      |\n",
      "| time/                 |          |\n",
      "|    fps                | 921      |\n",
      "|    iterations         | 3100     |\n",
      "|    time_elapsed       | 16       |\n",
      "|    total_timesteps    | 15500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.491   |\n",
      "|    explained_variance | -0.516   |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 4099     |\n",
      "|    policy_loss        | -0.497   |\n",
      "|    value_loss         | 6.28     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 123      |\n",
      "|    ep_rew_mean        | 123      |\n",
      "| time/                 |          |\n",
      "|    fps                | 921      |\n",
      "|    iterations         | 3200     |\n",
      "|    time_elapsed       | 17       |\n",
      "|    total_timesteps    | 16000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.406   |\n",
      "|    explained_variance | -23      |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 4199     |\n",
      "|    policy_loss        | 0.539    |\n",
      "|    value_loss         | 3.66     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 123      |\n",
      "|    ep_rew_mean        | 123      |\n",
      "| time/                 |          |\n",
      "|    fps                | 921      |\n",
      "|    iterations         | 3300     |\n",
      "|    time_elapsed       | 17       |\n",
      "|    total_timesteps    | 16500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.333   |\n",
      "|    explained_variance | -179     |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 4299     |\n",
      "|    policy_loss        | 0.198    |\n",
      "|    value_loss         | 0.161    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 117      |\n",
      "|    ep_rew_mean        | 117      |\n",
      "| time/                 |          |\n",
      "|    fps                | 921      |\n",
      "|    iterations         | 3400     |\n",
      "|    time_elapsed       | 18       |\n",
      "|    total_timesteps    | 17000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.416   |\n",
      "|    explained_variance | -7.12    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 4399     |\n",
      "|    policy_loss        | 0.0155   |\n",
      "|    value_loss         | 0.0132   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 79.7     |\n",
      "|    ep_rew_mean        | 79.7     |\n",
      "| time/                 |          |\n",
      "|    fps                | 918      |\n",
      "|    iterations         | 3500     |\n",
      "|    time_elapsed       | 19       |\n",
      "|    total_timesteps    | 17500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.571   |\n",
      "|    explained_variance | -0.807   |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 4499     |\n",
      "|    policy_loss        | 0.0226   |\n",
      "|    value_loss         | 0.00526  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 40.3     |\n",
      "|    ep_rew_mean        | 40.3     |\n",
      "| time/                 |          |\n",
      "|    fps                | 918      |\n",
      "|    iterations         | 3600     |\n",
      "|    time_elapsed       | 19       |\n",
      "|    total_timesteps    | 18000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.571   |\n",
      "|    explained_variance | -0.881   |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 4599     |\n",
      "|    policy_loss        | 0.0196   |\n",
      "|    value_loss         | 0.00214  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 12.5     |\n",
      "|    ep_rew_mean        | 12.5     |\n",
      "| time/                 |          |\n",
      "|    fps                | 913      |\n",
      "|    iterations         | 3700     |\n",
      "|    time_elapsed       | 20       |\n",
      "|    total_timesteps    | 18500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.616   |\n",
      "|    explained_variance | -3.23    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 4699     |\n",
      "|    policy_loss        | 0.0103   |\n",
      "|    value_loss         | 0.000715 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 11.5     |\n",
      "|    ep_rew_mean        | 11.5     |\n",
      "| time/                 |          |\n",
      "|    fps                | 910      |\n",
      "|    iterations         | 3800     |\n",
      "|    time_elapsed       | 20       |\n",
      "|    total_timesteps    | 19000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.62    |\n",
      "|    explained_variance | -20.9    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 4799     |\n",
      "|    policy_loss        | 0.0179   |\n",
      "|    value_loss         | 0.001    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 11.7     |\n",
      "|    ep_rew_mean        | 11.7     |\n",
      "| time/                 |          |\n",
      "|    fps                | 910      |\n",
      "|    iterations         | 3900     |\n",
      "|    time_elapsed       | 21       |\n",
      "|    total_timesteps    | 19500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.361   |\n",
      "|    explained_variance | -35      |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 4899     |\n",
      "|    policy_loss        | 0.00576  |\n",
      "|    value_loss         | 0.00572  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 12.9     |\n",
      "|    ep_rew_mean        | 12.9     |\n",
      "| time/                 |          |\n",
      "|    fps                | 911      |\n",
      "|    iterations         | 4000     |\n",
      "|    time_elapsed       | 21       |\n",
      "|    total_timesteps    | 20000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.542   |\n",
      "|    explained_variance | -0.687   |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 4999     |\n",
      "|    policy_loss        | 0.00868  |\n",
      "|    value_loss         | 0.000744 |\n",
      "------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<stable_baselines3.a2c.a2c.A2C at 0x2717b8670a0>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training the Algorithm while performing 20000 Steps (Actions)\n",
    "steps = 20000\n",
    "model.learn(total_timesteps=steps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing the Model with Method #1\n",
    "evaluate_policy(model, env, n_eval_episodes=10, render=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Closing the Prompt (Render)\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode:1 Score:11.0\n",
      "Episode:2 Score:9.0\n",
      "Episode:3 Score:9.0\n",
      "Episode:4 Score:10.0\n",
      "Episode:5 Score:8.0\n",
      "Episode:6 Score:10.0\n",
      "Episode:7 Score:10.0\n",
      "Episode:8 Score:10.0\n",
      "Episode:9 Score:10.0\n",
      "Episode:10 Score:10.0\n",
      "Episode:11 Score:8.0\n",
      "Episode:12 Score:10.0\n",
      "Episode:13 Score:10.0\n",
      "Episode:14 Score:10.0\n",
      "Episode:15 Score:10.0\n",
      "Episode:16 Score:11.0\n",
      "Episode:17 Score:10.0\n",
      "Episode:18 Score:8.0\n",
      "Episode:19 Score:8.0\n",
      "Episode:20 Score:10.0\n",
      "Episode:21 Score:9.0\n",
      "Episode:22 Score:9.0\n",
      "Episode:23 Score:10.0\n",
      "Episode:24 Score:8.0\n",
      "Episode:25 Score:11.0\n",
      "Episode:26 Score:10.0\n",
      "Episode:27 Score:10.0\n",
      "Episode:28 Score:10.0\n",
      "Episode:29 Score:9.0\n",
      "Episode:30 Score:10.0\n"
     ]
    }
   ],
   "source": [
    "# Testing the Model with Method #2\n",
    "\n",
    "# Selecting number of Episodes\n",
    "episodes = 30\n",
    "\n",
    "for episode in range(1, episodes+1):\n",
    "    # Reset the Enviroment\n",
    "    state = env.reset()\n",
    "    done = False\n",
    "    score = 0 \n",
    "    \n",
    "    while not done:\n",
    "        env.render()\n",
    "        # Predicting an Action\n",
    "        action, _states = model.predict(state)\n",
    "        # Applying the Action to the Enviroment\n",
    "        n_state, reward, done, info = env.step(action)\n",
    "        score+=reward\n",
    "    # Printing the Score per Episode\n",
    "    print('Episode:{} Score:{}'.format(episode, score))\n",
    "    \n",
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving the Model Weights\n",
    "model_name = \"A2C_carpole-v1_\" + str(steps) + \"steps\"\n",
    "model.save(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove to demonstrate saving and loading\n",
    "del model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name 'model' is not defined\n"
     ]
    }
   ],
   "source": [
    "# Checking if deleted \n",
    "try:\n",
    "    model\n",
    "except NameError as e:\n",
    "    print (e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code to use if importing a model built from a different Python version\n",
    "newer_python_version = sys.version_info.major == 3 and sys.version_info.minor >= 8\n",
    "\n",
    "custom_objects = {}\n",
    "\n",
    "if newer_python_version:\n",
    "    custom_objects = {\n",
    "        \"learning_rate\": 0.0,\n",
    "        \"lr_schedule\": lambda _: 0.0,\n",
    "        \"clip_range\": lambda _: 0.0,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the Model\n",
    "model = A2C.load(model_name, custom_objects=custom_objects)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode:1 Score:10.0\n",
      "Episode:2 Score:10.0\n",
      "Episode:3 Score:9.0\n",
      "Episode:4 Score:9.0\n",
      "Episode:5 Score:10.0\n",
      "Episode:6 Score:10.0\n",
      "Episode:7 Score:8.0\n",
      "Episode:8 Score:10.0\n",
      "Episode:9 Score:9.0\n",
      "Episode:10 Score:9.0\n",
      "Episode:11 Score:8.0\n",
      "Episode:12 Score:11.0\n",
      "Episode:13 Score:10.0\n",
      "Episode:14 Score:9.0\n",
      "Episode:15 Score:10.0\n",
      "Episode:16 Score:8.0\n",
      "Episode:17 Score:9.0\n",
      "Episode:18 Score:9.0\n",
      "Episode:19 Score:10.0\n",
      "Episode:20 Score:9.0\n",
      "Episode:21 Score:10.0\n",
      "Episode:22 Score:10.0\n",
      "Episode:23 Score:10.0\n",
      "Episode:24 Score:11.0\n",
      "Episode:25 Score:9.0\n",
      "Episode:26 Score:8.0\n",
      "Episode:27 Score:10.0\n",
      "Episode:28 Score:12.0\n",
      "Episode:29 Score:10.0\n",
      "Episode:30 Score:10.0\n"
     ]
    }
   ],
   "source": [
    "# Testing the Model after Loading\n",
    "\n",
    "# Selecting number of Episodes\n",
    "episodes = 30\n",
    "\n",
    "for episode in range(1, episodes+1):\n",
    "    # Reset the Enviroment\n",
    "    state = env.reset()\n",
    "    done = False\n",
    "    score = 0 \n",
    "    \n",
    "    while not done:\n",
    "        env.render()\n",
    "        # Predicting an Action\n",
    "        action, _states = model.predict(state)\n",
    "        # Applying the Action to the Enviroment\n",
    "        n_state, reward, done, info = env.step(action)\n",
    "        score+=reward\n",
    "    # Printing the Score per Episode\n",
    "    print('Episode:{} Score:{}'.format(episode, score))\n",
    "    \n",
    "env.close()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "34c1ba29f51c6797fe113b6c2daa785683b767bd515c07f3891e4aa372938bbd"
  },
  "kernelspec": {
   "display_name": "Python 3.8.0 ('Reinforcement': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
