{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Requirements\n",
    "import gymnasium as gym\n",
    "from stable_baselines3 import PPO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode #1\n",
      "Episode #1 Score: 27.0\n",
      "Episode #2\n",
      "Episode #2 Score: 35.0\n",
      "Episode #3\n",
      "Episode #3 Score: 52.0\n",
      "Episode #4\n",
      "Episode #4 Score: 11.0\n",
      "Episode #5\n",
      "Episode #5 Score: 27.0\n",
      "Episode #6\n",
      "Episode #6 Score: 20.0\n",
      "Episode #7\n",
      "Episode #7 Score: 35.0\n",
      "Episode #8\n",
      "Episode #8 Score: 22.0\n",
      "Episode #9\n",
      "Episode #9 Score: 18.0\n",
      "Episode #10\n",
      "Episode #10 Score: 12.0\n"
     ]
    }
   ],
   "source": [
    "# Creating the environment\n",
    "gym_env = gym.make(\"CartPole-v1\", render_mode=\"human\")\n",
    "observation, info = gym_env.reset()\n",
    "\n",
    "# Testing the environment\n",
    "for ep in range(1, 11):\n",
    "\n",
    "    print(f\"Episode #{ep}\")\n",
    "\n",
    "    # Resetting episode's variables\n",
    "    observation, info = gym_env.reset()\n",
    "    episode_over = False\n",
    "    score = 0\n",
    "\n",
    "    while not episode_over:\n",
    "        # Random action\n",
    "        action = gym_env.action_space.sample()\n",
    "        # Information after the random action has been applied\n",
    "        observation, reward, terminated, truncated, _ = gym_env.step(action)\n",
    "        score += reward\n",
    "        episode_over = terminated or truncated\n",
    "\n",
    "    print(f\"Episode #{ep} Score: {score}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n"
     ]
    }
   ],
   "source": [
    "model = PPO(\"MlpPolicy\", gym_env, verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 22.9     |\n",
      "|    ep_rew_mean     | 22.9     |\n",
      "| time/              |          |\n",
      "|    fps             | 46       |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 43       |\n",
      "|    total_timesteps | 2048     |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 26.9        |\n",
      "|    ep_rew_mean          | 26.9        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 46          |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 88          |\n",
      "|    total_timesteps      | 4096        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009422157 |\n",
      "|    clip_fraction        | 0.114       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.686      |\n",
      "|    explained_variance   | -0.00223    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 7.73        |\n",
      "|    n_updates            | 10          |\n",
      "|    policy_gradient_loss | -0.0176     |\n",
      "|    value_loss           | 54.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 35          |\n",
      "|    ep_rew_mean          | 35          |\n",
      "| time/                   |             |\n",
      "|    fps                  | 46          |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 133         |\n",
      "|    total_timesteps      | 6144        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009523393 |\n",
      "|    clip_fraction        | 0.0708      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.663      |\n",
      "|    explained_variance   | 0.0626      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 10.7        |\n",
      "|    n_updates            | 20          |\n",
      "|    policy_gradient_loss | -0.0198     |\n",
      "|    value_loss           | 38.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 48.6        |\n",
      "|    ep_rew_mean          | 48.6        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 46          |\n",
      "|    iterations           | 4           |\n",
      "|    time_elapsed         | 177         |\n",
      "|    total_timesteps      | 8192        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008795061 |\n",
      "|    clip_fraction        | 0.0906      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.629      |\n",
      "|    explained_variance   | 0.198       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 25.4        |\n",
      "|    n_updates            | 30          |\n",
      "|    policy_gradient_loss | -0.0185     |\n",
      "|    value_loss           | 58.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 62.8        |\n",
      "|    ep_rew_mean          | 62.8        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 46          |\n",
      "|    iterations           | 5           |\n",
      "|    time_elapsed         | 220         |\n",
      "|    total_timesteps      | 10240       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005041009 |\n",
      "|    clip_fraction        | 0.0392      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.617      |\n",
      "|    explained_variance   | 0.259       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 14.1        |\n",
      "|    n_updates            | 40          |\n",
      "|    policy_gradient_loss | -0.0125     |\n",
      "|    value_loss           | 56.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 76.5        |\n",
      "|    ep_rew_mean          | 76.5        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 46          |\n",
      "|    iterations           | 6           |\n",
      "|    time_elapsed         | 264         |\n",
      "|    total_timesteps      | 12288       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008124238 |\n",
      "|    clip_fraction        | 0.0933      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.593      |\n",
      "|    explained_variance   | 0.57        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 22.7        |\n",
      "|    n_updates            | 50          |\n",
      "|    policy_gradient_loss | -0.0155     |\n",
      "|    value_loss           | 56          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 93.9        |\n",
      "|    ep_rew_mean          | 93.9        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 46          |\n",
      "|    iterations           | 7           |\n",
      "|    time_elapsed         | 307         |\n",
      "|    total_timesteps      | 14336       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009074698 |\n",
      "|    clip_fraction        | 0.0812      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.581      |\n",
      "|    explained_variance   | 0.698       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 19.3        |\n",
      "|    n_updates            | 60          |\n",
      "|    policy_gradient_loss | -0.0115     |\n",
      "|    value_loss           | 43          |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 109          |\n",
      "|    ep_rew_mean          | 109          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 46           |\n",
      "|    iterations           | 8            |\n",
      "|    time_elapsed         | 351          |\n",
      "|    total_timesteps      | 16384        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0077523952 |\n",
      "|    clip_fraction        | 0.0592       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.556       |\n",
      "|    explained_variance   | 0.78         |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 19.5         |\n",
      "|    n_updates            | 70           |\n",
      "|    policy_gradient_loss | -0.00849     |\n",
      "|    value_loss           | 44.3         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 127         |\n",
      "|    ep_rew_mean          | 127         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 46          |\n",
      "|    iterations           | 9           |\n",
      "|    time_elapsed         | 394         |\n",
      "|    total_timesteps      | 18432       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006469762 |\n",
      "|    clip_fraction        | 0.0799      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.576      |\n",
      "|    explained_variance   | 0.928       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 3.66        |\n",
      "|    n_updates            | 80          |\n",
      "|    policy_gradient_loss | -0.0115     |\n",
      "|    value_loss           | 19.8        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 147          |\n",
      "|    ep_rew_mean          | 147          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 46           |\n",
      "|    iterations           | 10           |\n",
      "|    time_elapsed         | 438          |\n",
      "|    total_timesteps      | 20480        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0050013484 |\n",
      "|    clip_fraction        | 0.0712       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.581       |\n",
      "|    explained_variance   | 0.921        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 2.49         |\n",
      "|    n_updates            | 90           |\n",
      "|    policy_gradient_loss | -0.0096      |\n",
      "|    value_loss           | 19.3         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 165          |\n",
      "|    ep_rew_mean          | 165          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 46           |\n",
      "|    iterations           | 11           |\n",
      "|    time_elapsed         | 481          |\n",
      "|    total_timesteps      | 22528        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0034958078 |\n",
      "|    clip_fraction        | 0.0284       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.544       |\n",
      "|    explained_variance   | 0.45         |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 19.1         |\n",
      "|    n_updates            | 100          |\n",
      "|    policy_gradient_loss | -0.00682     |\n",
      "|    value_loss           | 56.5         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 183         |\n",
      "|    ep_rew_mean          | 183         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 46          |\n",
      "|    iterations           | 12          |\n",
      "|    time_elapsed         | 524         |\n",
      "|    total_timesteps      | 24576       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011786232 |\n",
      "|    clip_fraction        | 0.131       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.558      |\n",
      "|    explained_variance   | 0.957       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.526       |\n",
      "|    n_updates            | 110         |\n",
      "|    policy_gradient_loss | -0.0119     |\n",
      "|    value_loss           | 6.94        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 201         |\n",
      "|    ep_rew_mean          | 201         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 46          |\n",
      "|    iterations           | 13          |\n",
      "|    time_elapsed         | 568         |\n",
      "|    total_timesteps      | 26624       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006881569 |\n",
      "|    clip_fraction        | 0.0389      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.567      |\n",
      "|    explained_variance   | 0.974       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.546       |\n",
      "|    n_updates            | 120         |\n",
      "|    policy_gradient_loss | -0.00784    |\n",
      "|    value_loss           | 5.57        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 218         |\n",
      "|    ep_rew_mean          | 218         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 46          |\n",
      "|    iterations           | 14          |\n",
      "|    time_elapsed         | 611         |\n",
      "|    total_timesteps      | 28672       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003958931 |\n",
      "|    clip_fraction        | 0.0582      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.559      |\n",
      "|    explained_variance   | 0.00296     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 10.7        |\n",
      "|    n_updates            | 130         |\n",
      "|    policy_gradient_loss | -0.00645    |\n",
      "|    value_loss           | 26.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 234         |\n",
      "|    ep_rew_mean          | 234         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 46          |\n",
      "|    iterations           | 15          |\n",
      "|    time_elapsed         | 655         |\n",
      "|    total_timesteps      | 30720       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011570595 |\n",
      "|    clip_fraction        | 0.0646      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.521      |\n",
      "|    explained_variance   | 0.48        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.096       |\n",
      "|    n_updates            | 140         |\n",
      "|    policy_gradient_loss | -0.00329    |\n",
      "|    value_loss           | 1.7         |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 250       |\n",
      "|    ep_rew_mean          | 250       |\n",
      "| time/                   |           |\n",
      "|    fps                  | 46        |\n",
      "|    iterations           | 16        |\n",
      "|    time_elapsed         | 698       |\n",
      "|    total_timesteps      | 32768     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0124906 |\n",
      "|    clip_fraction        | 0.094     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -0.511    |\n",
      "|    explained_variance   | 0.759     |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 0.0715    |\n",
      "|    n_updates            | 150       |\n",
      "|    policy_gradient_loss | -0.00743  |\n",
      "|    value_loss           | 1.02      |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 269         |\n",
      "|    ep_rew_mean          | 269         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 46          |\n",
      "|    iterations           | 17          |\n",
      "|    time_elapsed         | 742         |\n",
      "|    total_timesteps      | 34816       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003347285 |\n",
      "|    clip_fraction        | 0.0136      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.491      |\n",
      "|    explained_variance   | 0.331       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.00786     |\n",
      "|    n_updates            | 160         |\n",
      "|    policy_gradient_loss | -0.000944   |\n",
      "|    value_loss           | 0.646       |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 285          |\n",
      "|    ep_rew_mean          | 285          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 46           |\n",
      "|    iterations           | 18           |\n",
      "|    time_elapsed         | 785          |\n",
      "|    total_timesteps      | 36864        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0057763183 |\n",
      "|    clip_fraction        | 0.0384       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.506       |\n",
      "|    explained_variance   | -0.00237     |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.0415       |\n",
      "|    n_updates            | 170          |\n",
      "|    policy_gradient_loss | -0.00165     |\n",
      "|    value_loss           | 0.395        |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 307          |\n",
      "|    ep_rew_mean          | 307          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 46           |\n",
      "|    iterations           | 19           |\n",
      "|    time_elapsed         | 828          |\n",
      "|    total_timesteps      | 38912        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0053485595 |\n",
      "|    clip_fraction        | 0.054        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.52        |\n",
      "|    explained_variance   | 0.0838       |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.00699      |\n",
      "|    n_updates            | 180          |\n",
      "|    policy_gradient_loss | -0.00245     |\n",
      "|    value_loss           | 0.256        |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 323         |\n",
      "|    ep_rew_mean          | 323         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 46          |\n",
      "|    iterations           | 20          |\n",
      "|    time_elapsed         | 872         |\n",
      "|    total_timesteps      | 40960       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009621229 |\n",
      "|    clip_fraction        | 0.0829      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.521      |\n",
      "|    explained_variance   | 0.203       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0103      |\n",
      "|    n_updates            | 190         |\n",
      "|    policy_gradient_loss | -0.0041     |\n",
      "|    value_loss           | 0.162       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 339         |\n",
      "|    ep_rew_mean          | 339         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 46          |\n",
      "|    iterations           | 21          |\n",
      "|    time_elapsed         | 916         |\n",
      "|    total_timesteps      | 43008       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003922933 |\n",
      "|    clip_fraction        | 0.0352      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.494      |\n",
      "|    explained_variance   | 0.0872      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.00868    |\n",
      "|    n_updates            | 200         |\n",
      "|    policy_gradient_loss | -0.00209    |\n",
      "|    value_loss           | 0.0992      |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 354          |\n",
      "|    ep_rew_mean          | 354          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 46           |\n",
      "|    iterations           | 22           |\n",
      "|    time_elapsed         | 959          |\n",
      "|    total_timesteps      | 45056        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0037521678 |\n",
      "|    clip_fraction        | 0.0594       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.492       |\n",
      "|    explained_variance   | 0.247        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.0294       |\n",
      "|    n_updates            | 210          |\n",
      "|    policy_gradient_loss | -0.00509     |\n",
      "|    value_loss           | 0.0631       |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 371          |\n",
      "|    ep_rew_mean          | 371          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 46           |\n",
      "|    iterations           | 23           |\n",
      "|    time_elapsed         | 1003         |\n",
      "|    total_timesteps      | 47104        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0025015008 |\n",
      "|    clip_fraction        | 0.0192       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.493       |\n",
      "|    explained_variance   | 0.0862       |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.00951      |\n",
      "|    n_updates            | 220          |\n",
      "|    policy_gradient_loss | -0.00045     |\n",
      "|    value_loss           | 0.0378       |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 387          |\n",
      "|    ep_rew_mean          | 387          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 46           |\n",
      "|    iterations           | 24           |\n",
      "|    time_elapsed         | 1046         |\n",
      "|    total_timesteps      | 49152        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0032272446 |\n",
      "|    clip_fraction        | 0.0411       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.465       |\n",
      "|    explained_variance   | 0.0799       |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.00223     |\n",
      "|    n_updates            | 230          |\n",
      "|    policy_gradient_loss | -0.00191     |\n",
      "|    value_loss           | 0.0235       |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | 400         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 46          |\n",
      "|    iterations           | 25          |\n",
      "|    time_elapsed         | 1089        |\n",
      "|    total_timesteps      | 51200       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002826987 |\n",
      "|    clip_fraction        | 0.0179      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.455      |\n",
      "|    explained_variance   | 0.0137      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.00468     |\n",
      "|    n_updates            | 240         |\n",
      "|    policy_gradient_loss | -0.00228    |\n",
      "|    value_loss           | 0.0161      |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<stable_baselines3.ppo.ppo.PPO at 0x2344ffc3800>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "STEPS = 50_000\n",
    "\n",
    "observation, info = gym_env.reset()\n",
    "\n",
    "model.learn(total_timesteps=STEPS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode #1\n",
      "Episode #1 Score: 500.0\n",
      "Episode #2\n",
      "Episode #2 Score: 500.0\n",
      "Episode #3\n",
      "Episode #3 Score: 500.0\n",
      "Episode #4\n",
      "Episode #4 Score: 500.0\n",
      "Episode #5\n",
      "Episode #5 Score: 500.0\n",
      "Episode #6\n",
      "Episode #6 Score: 500.0\n",
      "Episode #7\n",
      "Episode #7 Score: 500.0\n",
      "Episode #8\n",
      "Episode #8 Score: 500.0\n",
      "Episode #9\n",
      "Episode #9 Score: 500.0\n",
      "Episode #10\n",
      "Episode #10 Score: 500.0\n"
     ]
    }
   ],
   "source": [
    "observation, info = gym_env.reset()\n",
    "\n",
    "# Testing the model in 10 episodes\n",
    "for ep in range(1, 11):\n",
    "\n",
    "    print(f\"Episode #{ep}\")\n",
    "\n",
    "    # Resetting episode's variables\n",
    "    observation, info = gym_env.reset()\n",
    "    episode_over = False\n",
    "    score = 0\n",
    "\n",
    "    while not episode_over:\n",
    "        # Model's action prediction based on observation\n",
    "        action, _ = model.predict(observation, deterministic=True)\n",
    "        # Information after the predicted action has been applied\n",
    "        observation, reward, terminated, truncated, _ = gym_env.step(action)\n",
    "        score += reward\n",
    "        episode_over = terminated or truncated\n",
    "\n",
    "    print(f\"Episode #{ep} Score: {score}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving the model's weights\n",
    "model_name = \"PPO_carpole-v1_\" + str(STEPS) + \"steps\"\n",
    "model.save(model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the model\n",
    "model = PPO.load(model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode #1\n",
      "Episode #1 Score: 500.0\n",
      "Episode #2\n",
      "Episode #2 Score: 500.0\n",
      "Episode #3\n",
      "Episode #3 Score: 500.0\n",
      "Episode #4\n",
      "Episode #4 Score: 500.0\n",
      "Episode #5\n",
      "Episode #5 Score: 500.0\n",
      "Episode #6\n",
      "Episode #6 Score: 500.0\n",
      "Episode #7\n",
      "Episode #7 Score: 500.0\n",
      "Episode #8\n",
      "Episode #8 Score: 500.0\n",
      "Episode #9\n",
      "Episode #9 Score: 500.0\n",
      "Episode #10\n",
      "Episode #10 Score: 500.0\n"
     ]
    }
   ],
   "source": [
    "observation, info = gym_env.reset()\n",
    "\n",
    "# Testing the model in 10 episodes\n",
    "for ep in range(1, 11):\n",
    "\n",
    "    print(f\"Episode #{ep}\")\n",
    "\n",
    "    # Resetting episode's variables\n",
    "    observation, info = gym_env.reset()\n",
    "    episode_over = False\n",
    "    score = 0\n",
    "\n",
    "    while not episode_over:\n",
    "        # Model's action prediction based on observation\n",
    "        action, _ = model.predict(observation, deterministic=True)\n",
    "        # Information after the predicted action has been applied\n",
    "        observation, reward, terminated, truncated, _ = gym_env.step(action)\n",
    "        score += reward\n",
    "        episode_over = terminated or truncated\n",
    "\n",
    "    print(f\"Episode #{ep} Score: {score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gym_env.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
